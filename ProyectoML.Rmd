---
title: "Indicadores de salud para el corazón."
subtitle: "Modelos lineales. Grado en Ciencia de Datos- UV"
author: "Gema Bravo Aguilera, Sandra Paniagua Sanchez, Wilson Paul Portillo Barriga."
date:  "`r Sys.Date()`"  
params:
  lang: ES
lang: "`r switch(params$lang, ES = 'es-ES', EN = 'en-US')`"
output:
  html_document: default
  word_document: default
  pdf_document: default
---


```{r setup, cache = F,  message = F, warning = F, tidy = F, include=FALSE}
# CONFIGURACIÓN GENERAL
library(knitr)
options(width = 100)

opts_chunk$set(echo=F, message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 200, tidy = F, cache.path = '.cache/', fig.path = './figura/')

knit_hooks$set(inline = function(x) {
  
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})

```

```{r, echo = FALSE, include=FALSE}

# Especificamos las librerías necesarias en esta lista

packages = c("tidyverse","knitr", "lubridate", "readr", "dplyr", "forcats", "lubridate", "magrittr", "stringr", "tibble", "tidyr", "datasets", "RColorBrewer","nycflights13", "base", "datasets", "ggplot2", "plotly", "highcharter")

package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE,repos='http://cran.rediris.es')
  }
  library(x, character.only = TRUE)
})

search()

```

\bigskip

\bigskip

\noindent\makebox[\linewidth]{\rule{\textwidth}{0.4pt}}

\bigskip

\tableofcontents

\bigskip

\noindent\makebox[\linewidth]{\rule{\textwidth}{0.4pt}}


\newpage



## 1. Introducción del trabajo

El objetivo de este trabajo es analizar los datos recogidos por 





# 1.1. Carga de datos

```{r}
data <- read_csv("data/heart_disease_health_indicators_BRFSS2015.csv")
```


# 1.2.Transformación de datos

En los datos cargados la variable Age toma valores numéricos (1 al 13) que en
verdad se corresponden con una variable factor donde se representan los grupos 
de edad. 

```{r}

data$Age <- factor(data$Age,                                   
                   levels=c(1,2,3,4,5,6,7,8,9,10,11,12,13),
                   labels= c("Edad 18 hasta 24", "Edad 25 hasta 29", "Edad 30 hasta 34", "Edad 35 hasta 39", "Edad 40 hasta 44", "Edad 45 hasta 49", "Edad 50 hasta 54", "Edad 55 hasta 59", "Edad 60 hasta 64", "Edad 65 hasta 69", "Edad 70 hasta 74", "Edad 75 hasta 79", "Edad 80 o mas"))

data$Diabetes <- as.factor(data$Diabetes)
data$GenHlth <- as.factor(data$GenHlth)
data$Education <- as.factor(data$Education)
data$Income <- as.factor(data$Income)


datos <- data %>% 
  rename(Enfermedad_Cardiaca_Ataque = HeartDiseaseorAttack,
                         Fumador = Smoker,
                         Verduras = Veggies,
                         Salud_Mental = MentHlth,
                         Educacion = Education,
                         Presion_Sanginea_Alta = HighBP,
                         Ataque = Stroke,
                         Consumo_Alcohol = HvyAlcoholConsump,  #Hombre + 14 bebidas alcholicas/semana
                                                               #mujer + 7 bebidas alcholicas/semana
                         Salud_Fisica = PhysHlth,
                         Ingreso = Income,
                         Colesterol_Alto = HighChol,
                         Cuidado_Salud = AnyHealthcare,
                         Dificultad_Andar = DiffWalk,
                         Control_Colesterol = CholCheck,
                         Actividad_Fisica = PhysActivity,
                         No_Doctor_Caro = NoDocbcCost,
                         Sexo = Sex,
                         IMC = BMI,
                         Frutas = Fruits,
                         Salud_General = GenHlth,
                         Edad = Age) # 13 categorias de edad

```



# 2. Validación para medir la predictividad del modelo

Para empezar a trabajar con nuestros datos, vamos a dividirlos en validación y entrenamiento. Y generaremos nuestro modelo a partir de los datos almacenados en la variable entrenamiento y lo comprobaremos con los datos almacenados en la variable test.

```{r}

set.seed(12345)

# Establecemos el porcentaje de observaciones para el conjunto de entrenamiento y prueba
porcentaje_entrenamiento <- 0.7

# Obtenemos el número de observaciones para el entrenamiento
observaciones <- round(porcentaje_entrenamiento * nrow(data)) 

seleccion <- sample(nrow(data), observaciones)
entrenamiento <- datos[seleccion,]          # Conjunto de entrenamiento
test <- datos[-seleccion,]                  # Conjunto de validación
```

Lo primero que haremos será comprobar la capacidad de predicción del modelo lineal.

Como variable respuesta tenemos: Enfermedad_Cardiaca_Ataque

Ya que nos interesa saber de que depende este evento, por ello usamos 
el resto de variables como predictoras. Estimamos los modelos usando el conjunto de datos del banco de entrenamiento.


```{r}
ajuste <- glm(Enfermedad_Cardiaca_Ataque ~ ., family = "binomial",data=entrenamiento)
```
Ahora vamos a elegir las variables que mejor que ajustan segun su AIC

```{r}
step(ajuste)
```


```{r}
ajuste_bueno <- glm(Enfermedad_Cardiaca_Ataque ~ Presion_Sanginea_Alta + Colesterol_Alto + 
    Control_Colesterol + Fumador + Ataque + Diabetes + Actividad_Fisica + 
    Verduras + Consumo_Alcohol + No_Doctor_Caro + Salud_General + 
    Salud_Mental + Dificultad_Andar + Sexo + Edad + Educacion + 
    Ingreso, family = "binomial", data = entrenamiento)
summary(ajuste_bueno)
```

En este caso podemos ver que la formula de regresion quedaria tal que:

Enfermedad_Cardiaca_Ataque = b0 + b1Presion_Sanginea_Alta + b2Colesterol_Alto + b3Fumador + b4Ataque + b5Diabetes + b6Salud_General + b7Salud_Fisica + b8Dificultad_Andar + b9Ingreso.

```{r}
library(ResourceSelection)
hoslem.test(entrenamiento$Enfermedad_Cardiaca_Ataque, fitted(ajuste_bueno), g = 8)
```

Como podemos observar en el resultado del test, tenemos un p-valor muy pequeño(p-valor = 2.2e-16), con lo que podemos concluir que  rechazamos nuestra hipotesis nula lo cual significaria que los datos no se ajustan al modelo.
El problema es la asumcion de probabilidad incremental en forma de inversa logistica. Nuestras variables parecen que no se relacionan linealmente con el logit de la probabilidad. 




# COMPROBACIÓN ERROR CUADRÁTICO MEDIO

```{r}
(ecm_ajuste <- mean(ajuste_bueno$residuals^2)) #  Error Cuadrático Medio de ajuste
```

La bondad del ajuste de modelo nos  indica que en promedio, los  residuos al 
cuadrado tienen una  discrepancia de 0.071 unidades.

Esto nos indica que el modelo no  ajusta perfectamente los datos y hay una
cierta cantidad de variabilidad no explicada por el modelo.

```{r}
prediccion <- predict(ajuste_bueno,test)
(ecm <- mean((test$Enfermedad_Cardiaca_Ataque-prediccion)^2)) # Error Cuadrático Medio de predicción
```
Con esto comprobamos que el error de predicción es mayor que el ajustado y que
son casi igual de buenos uno que otro.

# CURVA ROC

```{r}
library(pROC)
par.roc <- roc(test$Enfermedad_Cardiaca_Ataque, prediccion)
par.roc
plot(par.roc)



```

La capacidad de clasifciación de este modelo es alta, porque el area bajo de la curva ROC es 0.8477 con un intervalo de confianza de (-), lo que indica claramente que es un buen modelo.




# ALTERNATIVA:

```{r}

```





