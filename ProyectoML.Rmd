---
title: "Indicadores de salud para el corazón."
subtitle: "Modelos lineales. Grado en Ciencia de Datos- UV"
author: "Gema Bravo Aguilera, Sandra Paniagua Sanchez, Wilson Paul Portillo Barriga."
date:  "`r Sys.Date()`"  
params:
  lang: ES
lang: "`r switch(params$lang, ES = 'es-ES', EN = 'en-US')`"
output:
  html_document: default
  word_document: default
  pdf_document: default
---


```{r setup, cache = F,  message = F, warning = F, tidy = F, include=FALSE}
# CONFIGURACIÓN GENERAL
library(knitr)
options(width = 100)

opts_chunk$set(echo=F, message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 200, tidy = F, cache.path = '.cache/', fig.path = './figura/')

knit_hooks$set(inline = function(x) {
  
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})

```

```{r, echo = FALSE, include=FALSE}

# Especificamos las librerías necesarias en esta lista

packages = c("tidyverse","knitr", "lubridate", "readr", "dplyr", "forcats", "lubridate", "magrittr", "stringr", "tibble", "tidyr", "datasets", "RColorBrewer","nycflights13", "base", "datasets", "ggplot2", "plotly", "highcharter")

package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE,repos='http://cran.rediris.es')
  }
  library(x, character.only = TRUE)
})

search()

```

\bigskip

\bigskip

\noindent\makebox[\linewidth]{\rule{\textwidth}{0.4pt}}

\bigskip

\tableofcontents

\bigskip

\noindent\makebox[\linewidth]{\rule{\textwidth}{0.4pt}}


\newpage




## *1. Carga de datos.*

```{r}
data <- read_csv("data/heart_disease_health_indicators_BRFSS2015.csv")
```


### Transformación de datos

En los datos cargados la variable Age toma valores numéricos (1 al 13) que en
verdad se corresponden con una variable factor donde se representan los grupos 
de edad. 

```{r}

data$Age <- factor(data$Age, levels=c(1,2,3,4,5,6,7,8,9,10,11,12,13),
                   labels= c("[18 a 24]", "[25 a 29]", "[30 a 34]", "[35 a 39]", "[40 a 44]", "[45 a 49]", "[50 a 54]", "[55 a 59]", "[60 a 64]", "[65 a 69]", "[70 a 74]", "[75 a 79]", "[80 o más]")) 

data$Diabetes <- as.factor(data$Diabetes)
data$GenHlth <- as.factor(data$GenHlth)
data$Education <- as.factor(data$Education)
data$Income <- as.factor(data$Income)


datos <- data %>% 
  rename(Enfermedad_Cardiaca_Ataque = HeartDiseaseorAttack,
                         Fumador = Smoker,
                         Verduras = Veggies,
                         Salud_Mental = MentHlth,
                         Educacion = Education,
                         Presion_Sanginea_Alta = HighBP,
                         Ataque = Stroke,
                         Consumo_Alcohol = HvyAlcoholConsump,  #Hombre + 14 bebidas alcholicas/semana
                                                               #mujer + 7 bebidas alcholicas/semana
                         Salud_Fisica = PhysHlth,
                         Ingreso = Income,
                         Colesterol_Alto = HighChol,
                         Cuidado_Salud = AnyHealthcare,
                         Dificultad_Andar = DiffWalk,
                         Control_Colesterol = CholCheck,
                         Actividad_Fisica = PhysActivity,
                         No_Doctor_Caro = NoDocbcCost,
                         Sexo = Sex,
                         IMC = BMI,
                         Frutas = Fruits,
                         Salud_General = GenHlth,
                         Edad = Age) # 13 categorias de edad

```

### Mostramos los datos

Hacemos un gráfico inicial para ver como se distribuyen los datos de las variables que creemos que pueden influir a la hora de tener una enfermedad cardiaca
```{r}
colores <- c("Hombre" = "#37a4d7",
             "Mujer" = "#9c3035")
datos3 <- datos %>%
      group_by(Edad,Sexo) %>% 
      filter(Enfermedad_Cardiaca_Ataque == 1) %>% # vemos los que han tenido enfermedad cardiaca o ataque por sexo
      count(Enfermedad_Cardiaca_Ataque) %>% 
      mutate(Sexo = ifelse(Sexo == 1, "Hombre", "Mujer")) %>%
      ungroup() %>% 
      arrange(factor(Edad))

datos3 %>% plot_ly(x = ~Edad, y = ~n, type = 'bar',color = ~ factor(Sexo), colors = colores) %>% 
      layout(xaxis = list(title = "Edades"),
             yaxis = list(title = "Cantidad de enfermedades cardiacas")) %>% 
      config(displayModeBar = FALSE)


datos4 <- datos %>% 
  group_by(Edad, Sexo, Fumador) %>% 
  filter(Enfermedad_Cardiaca_Ataque == 1) %>% # vemos los que han tenido enfermedad cardiaca o ataque por sexo y fumador
  count(Enfermedad_Cardiaca_Ataque) %>% 
  mutate(Sexo = ifelse(Sexo == 1, "Hombre", "Mujer")) %>%
  mutate(Fumador = ifelse(Fumador == 1, "Fumador", "No Fumador")) %>%
  ungroup() %>% 
  arrange(factor(Edad))

datos4 %>% 
  ggplot(aes(x = Edad, y = n, fill = Sexo)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Fumador) +
  labs(x = "Edades", y = "Cantidad de enfermedades cardiacas") +
  scale_fill_manual(values = colores) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = -35, hjust = 0))
```



Ahora mostramos en una tabla las variables del gráfico anterior junto con otras que también creemos que son importantes sin contar la edad

```{r}
library(DT)
datos %>% 
  group_by(Sexo, Fumador, Colesterol_Alto, Diabetes) %>% 
  mutate(Sexo = ifelse(Sexo == 1, "Hombre", "Mujer")) %>%
  mutate(Fumador = ifelse(Fumador == 1, "Fumador", "No Fumador")) %>% 
  mutate(Colesterol_Alto = ifelse(Colesterol_Alto == 1, "Colesterol alto", "No coresterol alto")) %>% 
  summarize(`Media Ataques` = round(mean(Enfermedad_Cardiaca_Ataque),2)) %>%
  DT::datatable(extensions = 'Buttons', 
               options = list(dom = 'Blfrtip', 
                              buttons = c('copy', 'csv', 'excel', 'pdf', 'print'), 
                              pageLength = 5, autoWidth = TRUE ))
```


## *2. Validación para medir la predictividad del modelo.*

Para empezar a trabajar con nuestros datos, vamos a dividirlos en validación y entrenamiento. Y generaremos nuestro modelo a partir de los datos almacenados en la variable entrenamiento y lo comprobaremos con los datos almacenados en la variable test.

```{r}

set.seed(12345)

# Establecemos el porcentaje de observaciones para el conjunto de entrenamiento y prueba
porcentaje_entrenamiento <- 0.7

# Obtenemos el número de observaciones para el entrenamiento
observaciones <- round(porcentaje_entrenamiento * nrow(data)) 

seleccion <- sample(nrow(data), observaciones)
entrenamiento <- datos[seleccion,]          # Conjunto de entrenamiento
test <- datos[-seleccion,]                  # Conjunto de validación
```

## AJUSTE NORMAL 

Lo primero que haremos será comprobar la capacidad de predicción del modelo lineal.

Como variable respuesta tenemos: Enfermedad_Cardiaca_Ataque

Ya que nos interesa saber de que depende este evento, por ello usamos 
el resto de variables como predictoras. Estimamos los modelos usando el conjunto de datos del banco de entrenamiento.


```{r}
ajuste <- glm(Enfermedad_Cardiaca_Ataque ~ ., family = "binomial",data=entrenamiento)
```
Ahora vamos a elegir las variables que mejor que ajustan segun su AIC


### Prediccion 

```{r}
prediccion <- predict(ajuste,test, type = "response")

#Hacemos que sea binario 
pred2 <- rep("0_Incorrect",length(test$Enfermedad_Cardiaca_Ataque))
pred2[prediccion > 0.5] <- "1_Correct"

#Lo ponemos en tabla
(tt<-table(test$Enfermedad_Cardiaca_Ataque, pred2))

#Calculando la matriz de confusión obtenemos que:

#Specifity:
spe_normal<-tt[1,1]/sum(tt[1,])
#Sensivity:
sen_normal<-tt[2,2]/sum(tt[2,])

cat('Sensitivity: ',sen_normal,'   Specifity: ',spe_normal)
tot<-(tt[1,1] + tt[2,2]) / sum(tt)
cat('Well-classified (Bayes): ',round(100*tot,2),'%')
porcentaje_normal <- round(100*tot,2)
```

## AJUSTE BUENO
```{r}
step(ajuste)
```


```{r}
ajuste_bueno <- glm(Enfermedad_Cardiaca_Ataque ~ Presion_Sanginea_Alta + Colesterol_Alto + 
    Control_Colesterol + Fumador + Ataque + Diabetes + Actividad_Fisica + 
    Verduras + Consumo_Alcohol + No_Doctor_Caro + Salud_General + 
    Salud_Mental + Dificultad_Andar + Sexo + Edad + Educacion + 
    Ingreso, family = "binomial", data = entrenamiento)
summary(ajuste_bueno)
```

En este caso podemos ver que la formula de regresion quedaria tal que:

Enfermedad_Cardiaca_Ataque = b0 + b1Presion_Sanginea_Alta + b2Colesterol_Alto + b3Fumador + b4Ataque + b5Diabetes + b6Salud_General + b7Salud_Mental + b8Dificultad_Andar + b9Ingreso + b10Sexo + b11Consumo_Alcohol + b12Control_Colesterol.


### Predicción


```{r}
prediccion <- predict(ajuste_bueno,test, type = "response")

#Hacemos que sea binario 
pred2 <- rep("0_Incorrect",length(test$Enfermedad_Cardiaca_Ataque))
pred2[prediccion > 0.5] <- "1_Correct"

#Lo ponemos en tabla
(tt<-table(test$Enfermedad_Cardiaca_Ataque, pred2))

#Calculando la matriz de confusión obtenemos que:

#Specifity:
spe_bueno<-tt[1,1]/sum(tt[1,])
#Sensivity:
sen_bueno<-tt[2,2]/sum(tt[2,])

cat('Sensitivity: ',sen_bueno,'   Specifity: ',spe_bueno)
tot<-(tt[1,1] + tt[2,2]) / sum(tt)
cat('Well-classified (Bayes): ',round(100*tot,2),'%')
porcentaje_bueno <- round(100*tot,2)

```


### Curva ROC

```{r}
library(pROC)
par.roc <- roc(test$Enfermedad_Cardiaca_Ataque, prediccion)


#La dibujamos
yi<-coords(par.roc, "best")
par(pty="s")
plot(par.roc,xlim=c(1,0))
points(spe_bueno,sen_bueno,col='blue')
text(spe_bueno,sen_bueno,'p=0.5',col='blue',pos=4)
text(spe_bueno,sen_bueno,'p=0.5',col='blue',pos=4)
points(yi[2],yi[3],col='red')
text(yi[2],yi[3],paste('p*=',round(yi[1],3)),col='red',pos='2')
text(0,0.1,paste('AUC=',round(par.roc$auc,3)),pos=2)
text(0,0,paste('95% CI:',round(ci(par.roc)[1],3),'-',round(ci(par.roc)[3],3)),pos=2)


```


### Test Hoslem

```{r}
library(ResourceSelection)
hoslem.test(entrenamiento$Enfermedad_Cardiaca_Ataque, fitted(ajuste_bueno), g = 8)
```

Como podemos observar en el resultado del test, tenemos un p-valor muy pequeño(p-valor = 2.2e-16), con lo que podemos concluir que  rechazamos nuestra hipotesis nula lo cual significaria que los datos no se ajustan al modelo.
El problema es la asumcion de probabilidad incremental en forma de inversa logistica. Nuestras variables parecen que no se relacionan linealmente con el logit de la probabilidad. 





## AJUSTE LASSO


Para empezar con el modelo de Lasso tendremos que estimar landa con validación cruzada de esta forma:


```{r}
library(glmnet)
x <- model.matrix(Enfermedad_Cardiaca_Ataque ~ .,entrenamiento)
y <- entrenamiento$Enfermedad_Cardiaca_Ataque #vector de variable respuesta

```



```{r}
set.seed(12345)
cv.lasso <- cv.glmnet(x,y,alpha=1, family = "binomial")
plot(cv.lasso)
min(cv.lasso$cvm) #Mínimo error cuadrático medio de predicción
cv.lasso$lambda.min  # Alcanza el mínimo ECM
cv.lasso$lambda.1se  # Regla de un error estándar

```


Segun esta grafica, podemos observar que necesitaremos entre 13 y 19 covariables ya que la primera linea sabemos que indica el ECM minimo en escala logaritmica con log(lamnda) = -7 aproximadamente y la siguiente linea de puntos verticales indica el valor de landa que estaria a menos de 1 error estandard. Por tanto, nos interesa elegir el numero de covariables que se relaciona en esa linea de puntos que aproximadamente será entre 12 y 13 covariables. 

Pero si aplicamos la regla de 1 error estandard, realmente no se distinguir entre los lamndas cercanos a este primero. El mas grande, utilizando las reglas de un error estandard, seria la segunda linea. El ECM en esta linea, será mas grande que en la primera pero se diferencian en menos de 1 error estandard entonces no podemos diferenciar y no podemos saber cual es mejor porque esta dentro del rango de error de medida. 
Habitualmente elegimos un lamnda entre estas lineas, con un redondeo de 3 decimales. Por tanto, lamnda que elegimos es 0.005.

Por lo tanto seguimos con incertidumbre, y esa incertidumbre la medimos con intervalos de confianza que se construyen con los errores estandard. Nos dice hasta que putno estoy convencido del valor. 

Utilizando $\lambda =$ `r round(cv.lasso$lambda.1se,3)`, el error de predicción es:
```{r}
x <- model.matrix(Enfermedad_Cardiaca_Ataque ~ .,test)
y <- test$Enfermedad_Cardiaca_Ataque #vector de variable respuesta

lasso.lambda1st <- glmnet(x,y,alpha=1,lambda=round(cv.lasso$lambda.1se,3))
pred.lasso.lambda1st <- predict(lasso.lambda1st,s=round(cv.lasso$lambda.1se,3),newx=x)
mean((pred.lasso.lambda1st-y)^2)
```
Una vez seleccionado el valor de $\lambda$, el tercer paso es recuperar todos los datos para obtener los estimadores lasso definitivos, comprobando qué predictores han quedado en el modelo (aquellos cuyo coeficiente sea distinto de cero):

```{r}
lasso_final <- glmnet(x,y,alpha=1,lambda =round(cv.lasso$lambda.1se,3))
coef(lasso_final)[coef(lasso_final)[,1] !=0,]
```


En este caso, aunque el error estimado de predicción sea un poco mayor, hemos reducido a la mitad el número de variables en el modelo.


### Test de Hoslem

```{r}
# library(ResourceSelection)
# hoslem.test(entrenamiento$Enfermedad_Cardiaca_Ataque, fitted(lasso_final), g = 8)
```


### Prediccion
```{r}
#Hacemos que sea binario 
pred2 <- rep("0_Incorrect",length(test$Enfermedad_Cardiaca_Ataque))
pred2[pred.lasso.lambda1st > 0.5] <- "1_Correct"  ####CAMBIAR ESTO PARA QUE NOS DEN MAS ATAQUES AL CORAZON

#Lo ponemos en tabla
(tt<-table(test$Enfermedad_Cardiaca_Ataque, pred2))

#Calculando la matriz de confusión obtenemos que:

#Specifity:
spe_lasso<-tt[1,1]/sum(tt[1,])
#Sensivity:
sen_lasso<-tt[2,2]/sum(tt[2,])

cat('Sensitivity: ',sen_lasso,'   Specifity: ',spe_lasso)
tot<-(tt[1,1] + tt[2,2]) / sum(tt)
cat('Well-classified (Bayes): ',round(100*tot,2),'%')
porcentaje_lasso <- round(100*tot,2)
```


### Curva ROC

```{r}
library(pROC)
par.roc <- roc(test$Enfermedad_Cardiaca_Ataque, pred.lasso.lambda1st)


#La dibujamos
yi<-coords(par.roc, "best")
par(pty="s")
plot(par.roc,xlim=c(1,0))
points(spe_lasso,sen_lasso,col='blue')
text(spe_lasso,sen_lasso,'p=0.5',col='blue',pos=4)
text(spe_lasso,sen_lasso,'p=0.5',col='blue',pos=4)
points(yi[2],yi[3],col='red')
text(yi[2],yi[3],paste('p*=',round(yi[1],3)),col='red',pos='2')
text(0,0.1,paste('AUC=',round(par.roc$auc,3)),pos=2)
text(0,0,paste('95% CI:',round(ci(par.roc)[1],3),'-',round(ci(par.roc)[3],3)),pos=2)


```


# 3. Comparar entre los tres ajustes
```{r}
#Ajuste normal
print(paste("Especificidad: ", spe_normal))
print(paste("Sensibilidad: ", sen_normal))
print(paste("Porcentaje: ", porcentaje_normal, "%"))

#Ajuste bueno
print(paste("Especificidad: ", spe_bueno))
print(paste("Sensibilidad: ", sen_bueno))
print(paste("Porcentaje: ", porcentaje_bueno, "%"))

#Ajuste lasso
print(paste("Especificidad: ", spe_lasso))
print(paste("Sensibilidad: ", sen_lasso))
print(paste("Porcentaje: ", porcentaje_lasso, "%"))



```


