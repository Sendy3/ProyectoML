---
title: "Indicadores de salud para el corazón."
subtitle: "Modelos lineales. Grado en Ciencia de Datos- UV"
author: "Gema Bravo Aguilera, Sandra Paniagua Sanchez, Wilson Paul Portillo Barriga."
date:  "`r Sys.Date()`"  
params:
  lang: ES
lang: "`r switch(params$lang, ES = 'es-ES', EN = 'en-US')`"
output:
  html_document: default
  word_document: default
  pdf_document: default
---


```{r setup, cache = F,  message = F, warning = F, tidy = F, include=FALSE}
# CONFIGURACIÓN GENERAL
library(knitr)
options(width = 100)

opts_chunk$set(echo=F, message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 200, tidy = F, cache.path = '.cache/', fig.path = './figura/')

knit_hooks$set(inline = function(x) {
  
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})

```

```{r, echo = FALSE, include=FALSE}

# Especificamos las librerías necesarias en esta lista

packages = c("tidyverse","knitr", "lubridate", "readr", "dplyr", "forcats", "lubridate", "magrittr", "stringr", "tibble", "tidyr", "datasets", "RColorBrewer","nycflights13", "base", "datasets", "ggplot2", "plotly", "highcharter")

package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE,repos='http://cran.rediris.es')
  }
  library(x, character.only = TRUE)
})

search()

```

\bigskip

\bigskip

\noindent\makebox[\linewidth]{\rule{\textwidth}{0.4pt}}

\bigskip

\tableofcontents

\bigskip

\noindent\makebox[\linewidth]{\rule{\textwidth}{0.4pt}}


\newpage



## 1. Introducción del trabajo

El objetivo de este trabajo es analizar los datos recogidos por 





# 1.1. Carga de datos

```{r}

data <- read_csv("data/heart_disease_health_indicators_BRFSS2015.csv")


```


# 1.2.Transformación de datos

En los datos cargados la variable Age toma valores numéricos (1 al 13) que en
verdad se corresponden con una variable factor donde se representan los grupos 
de edad. 

```{r}

data$Age <- factor(data$Age,                                   
                   levels=c(1,2,3,4,5,6,7,8,9,10,11,12,13),
                   labels= c("Edad 18 hasta 24", "Edad 25 hasta 29", "Edad 30 hasta 34", "Edad 35 hasta 39", "Edad 40 hasta 44", "Edad 45 hasta 49", "Edad 50 hasta 54", "Edad 55 hasta 59", "Edad 60 hasta 64", "Edad 65 hasta 69", "Edad 70 hasta 74", "Edad 75 hasta 79", "Edad 80 o mas"))



datos <- data %>% 
  rename(Enfermedad_Cardiaca_Ataque = HeartDiseaseorAttack,
                         Fumador = Smoker,
                         Verduras = Veggies,
                         Salud_Mental = MentHlth,
                         Educacion = Education,
                         Presion_Sanginea_Alta = HighBP,
                         Ataque = Stroke,
                         Consumo_Alcohol = HvyAlcoholConsump,  #Hombre + 14 bebidas alcholicas/semana
                                                               #mujer + 7 bebidas alcholicas/semana
                         Salud_Fisica = PhysHlth,
                         Ingreso = Income,
                         Colesterol_Alto = HighChol,
                         Cuidado_Salud = AnyHealthcare,
                         Dificultad_Andar = DiffWalk,
                         Control_Colesterol = CholCheck,
                         Actividad_Fisica = PhysActivity,
                         No_Doctor_Caro = NoDocbcCost,
                         Sexo = Sex,
                         IMC = BMI,
                         Frutas = Fruits,
                         Salud_General = GenHlth,
                         Edad = Age) # 13 categorias de edad

```



# 2. Validación para medir la predictividad del modelo

Para empezar a trabajar con nuestros datos, vamos a dividirlos en validación y entrenamiento. Y generaremos nuestro modelo a partir de los datos almacenados en la variable entrenamiento y lo comprobaremos con los datos almacenados en la variable test.

```{r}

set.seed(12345)

# Establecemos el porcentaje de observaciones para el conjunto de entrenamiento y prueba

porcentaje_entrenamiento <- 0.7

# Obtenemos el número de observaciones para el entrenamiento
observaciones <- round(porcentaje_entrenamiento * nrow(data)) 

seleccion <- sample(nrow(data), observaciones)
entrenamiento <- datos[seleccion,]          # Conjunto de entrenamiento
test <- datos[-seleccion,]                   # Conjunto de validación
```

Lo primero que haremos será comprobar la capacidad de predicción del 
modelo lineal.

Como variable respuesta tenemos: HeartDiseaseorAttack

Ya que nos interesa saber de que depende este evento, por ello usamos 
el resto de variables como predictoras. Estimamos los modelos usando el conjunto de datos del banco de entrenamiento.


```{r}
#
ajuste <- lm(Enfermedad_Cardiaca_Ataque ~ ., data=entrenamiento)
summary(ajuste)
```


Segun este resultado, vemos que existen varias variables que son importantes para predecir nuestra variable respuesta. Observamos que las variables en cuestion son: Presion_Sanginea_Alta + Colesterol_Alto + IMC + Fumador + Ataque + Diabetes + Consumo_Alcohol + No_Doctor_Caro + Salud_General + Salud_Fisica + Dificultad_Andar + Sexo + Ingreso + Age ("Age 60 to 64", "Age 65 to 69", "Age 70 to 74", "EdadAge 75 to 79", "Age 80 or older").

Y en menor medida tambien afecta a nuestra variable respuesta: Control_Colesterol + Frutas + Cuidado_Salud.

# COMPROBACIÓN ERROR CUADRÁTICO MEDIO


```{r}
(ecm_ajuste <- mean(ajuste$residuals^2)) #  Error Cuadrático Medio de ajuste

```

La bondad del ajuste de modelo nos  indica que en promedio, los  residuos al 
cuadrado tienen una  discrepancia de 0.071 unidades.

Esto nos indica que el modelo no  ajusta perfectamente los datos y hay una
cierta cantidad de variabilidad no explicada por el modelo.

```{r}
prediccion <- predict(ajuste,test)
(ecm <- mean((test$Enfermedad_Cardiaca_Ataque-prediccion)^2)) # Error Cuadrático Medio de predicción
```
Con esto comprobamos que el error de predicción es mayor que el ajustado y que
son casi igual de buenos uno que otro.

#CORRELACIÓN 

Vamos a ver que tipo de correlacion tienen las variables con nuestra variable respuesta para confirmar si estas son las variables que realmente nos ayudaran en nuestra predicción:
```{r}
data2 <- datos[-20] #Quitamos la variable Age porque es factor
cor(data2)
```
Dadas las cifras observadas en la columna de Enfermedad_Cardiaca_Ataque, las variables que probablemente expliquen mejor esta variable dado que tienen los valores mas altos de correlacion en valor absoluto se corresponden con: Presion_Sanginea_Alta + Colesterol_Alto +  Fumador + Ataque + Diabetes + Salud_General + Salud_Fisica + Dificultad_Andar +  Ingreso.

Como podemos observar, la mayoria de las variables que anteriormente habiamos seleccionado, hemos obtenido que estan directamente correlacionadas. 

Por tanto, vamos a elegir las que coinciden en la correlacion y en el summary anterior:

```{r}
ajuste_bueno <- lm(Enfermedad_Cardiaca_Ataque ~ Presion_Sanginea_Alta + Colesterol_Alto +  Fumador + Ataque + Diabetes + Salud_General + Salud_Fisica + Dificultad_Andar +  Ingreso, data=entrenamiento)
summary(ajuste_bueno)
```
En este caso podemos ver que la formula de regresion quedaria tal que:

Enfermedad_Cardiaca_Ataque = b0 + b1Presion_Sanginea_Alta + b2Colesterol_Alto + b3Fumador + b4Ataque + b5Diabetes + b6Salud_General + b7Salud_Fisica + b8Dificultad_Andar + b9Ingreso.


El porcentage de variabilidad que queda explicada en las otras variables es 0.1284 

