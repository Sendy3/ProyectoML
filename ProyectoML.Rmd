---
title: "Indicadores de salud para el corazón."
subtitle: "Modelos lineales. Grado en Ciencia de Datos- UV"
author: "Gema Bravo Aguilera, Sandra Paniagua Sanchez, Wilson Paul Portillo Barriga."
date:  "`r Sys.Date()`"  
params:
  lang: ES
lang: "`r switch(params$lang, ES = 'es-ES', EN = 'en-US')`"
output:
  html_document: default
  word_document: default
  pdf_document: default
---


```{r setup, cache = F,  message = F, warning = F, tidy = F, include=FALSE}
# CONFIGURACIÓN GENERAL
library(knitr)
options(width = 100)

opts_chunk$set(echo=F, message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 200, tidy = F, cache.path = '.cache/', fig.path = './figura/')

knit_hooks$set(inline = function(x) {
  
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})

```

```{r, echo = FALSE, include=FALSE}

# Especificamos las librerías necesarias en esta lista

packages = c("tidyverse","knitr", "lubridate", "readr", "dplyr", "forcats", "lubridate", "magrittr", "stringr", "tibble", "tidyr", "datasets", "RColorBrewer","nycflights13", "base", "datasets", "ggplot2", "plotly", "highcharter")

package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE,repos='http://cran.rediris.es')
  }
  library(x, character.only = TRUE)
})

search()

```

\bigskip

\bigskip

\noindent\makebox[\linewidth]{\rule{\textwidth}{0.4pt}}

\bigskip

\tableofcontents

\bigskip

\noindent\makebox[\linewidth]{\rule{\textwidth}{0.4pt}}


\newpage



## 1. Introducción del trabajo

El objetivo de este trabajo es analizar los datos recogidos por 





# 1.1. Carga de datos

```{r}
data <- read_csv("data/heart_disease_health_indicators_BRFSS2015.csv")
```


# 1.2.Transformación de datos

En los datos cargados la variable Age toma valores numéricos (1 al 13) que en
verdad se corresponden con una variable factor donde se representan los grupos 
de edad. 

```{r}

data$Age <- factor(data$Age,                                   
                   levels=c(1,2,3,4,5,6,7,8,9,10,11,12,13),
                   labels= c("Edad 18 hasta 24", "Edad 25 hasta 29", "Edad 30 hasta 34", "Edad 35 hasta 39", "Edad 40 hasta 44", "Edad 45 hasta 49", "Edad 50 hasta 54", "Edad 55 hasta 59", "Edad 60 hasta 64", "Edad 65 hasta 69", "Edad 70 hasta 74", "Edad 75 hasta 79", "Edad 80 o mas"))

data$Diabetes <- as.factor(data$Diabetes)
data$GenHlth <- as.factor(data$GenHlth)
data$Education <- as.factor(data$Education)
data$Income <- as.factor(data$Income)


datos <- data %>% 
  rename(Enfermedad_Cardiaca_Ataque = HeartDiseaseorAttack,
                         Fumador = Smoker,
                         Verduras = Veggies,
                         Salud_Mental = MentHlth,
                         Educacion = Education,
                         Presion_Sanginea_Alta = HighBP,
                         Ataque = Stroke,
                         Consumo_Alcohol = HvyAlcoholConsump,  #Hombre + 14 bebidas alcholicas/semana
                                                               #mujer + 7 bebidas alcholicas/semana
                         Salud_Fisica = PhysHlth,
                         Ingreso = Income,
                         Colesterol_Alto = HighChol,
                         Cuidado_Salud = AnyHealthcare,
                         Dificultad_Andar = DiffWalk,
                         Control_Colesterol = CholCheck,
                         Actividad_Fisica = PhysActivity,
                         No_Doctor_Caro = NoDocbcCost,
                         Sexo = Sex,
                         IMC = BMI,
                         Frutas = Fruits,
                         Salud_General = GenHlth,
                         Edad = Age) # 13 categorias de edad
head(datos)

```



# 2. Validación para medir la predictividad del modelo

Para empezar a trabajar con nuestros datos, vamos a dividirlos en validación y entrenamiento. Y generaremos nuestro modelo a partir de los datos almacenados en la variable entrenamiento y lo comprobaremos con los datos almacenados en la variable test.

```{r}

set.seed(12345)

# Establecemos el porcentaje de observaciones para el conjunto de entrenamiento y prueba
porcentaje_entrenamiento <- 0.7

# Obtenemos el número de observaciones para el entrenamiento
observaciones <- round(porcentaje_entrenamiento * nrow(data)) 

seleccion <- sample(nrow(data), observaciones)
entrenamiento <- datos[seleccion,]          # Conjunto de entrenamiento
test <- datos[-seleccion,]                  # Conjunto de validación
```

Lo primero que haremos será comprobar la capacidad de predicción del modelo lineal.

Como variable respuesta tenemos: Enfermedad_Cardiaca_Ataque

Ya que nos interesa saber de que depende este evento, por ello usamos 
el resto de variables como predictoras. Estimamos los modelos usando el conjunto de datos del banco de entrenamiento.


```{r}
ajuste <- glm(Enfermedad_Cardiaca_Ataque ~ ., family = "binomial",data=entrenamiento)
```
Ahora vamos a elegir las variables que mejor que ajustan segun su AIC

```{r}
#step(ajuste)
```


```{r}
ajuste_bueno <- glm(Enfermedad_Cardiaca_Ataque ~ Presion_Sanginea_Alta + Colesterol_Alto + 
    Control_Colesterol + Fumador + Ataque + Diabetes + Actividad_Fisica + 
    Verduras + Consumo_Alcohol + No_Doctor_Caro + Salud_General + 
    Salud_Mental + Dificultad_Andar + Sexo + Edad + Educacion + 
    Ingreso, family = "binomial", data = entrenamiento)
summary(ajuste_bueno)
```

En este caso podemos ver que la formula de regresion quedaria tal que:

Enfermedad_Cardiaca_Ataque = b0 + b1Presion_Sanginea_Alta + b2Colesterol_Alto + b3Fumador + b4Ataque + b5Diabetes + b6Salud_General + b7Salud_Fisica + b8Dificultad_Andar + b9Ingreso.

# Graficos: Validacion del modelo

El modelo lineal normal homocedástico basa sus resultados en diversas hipótesis que podrían no ser adecuadas para nuestros datos: linealidad, normalidad i homocedasticidad. Es conveniente contrastar estas hipótesis mediante el análisis de los residuos.


```{r}
par(mfrow = c(2,2))
plot(ajuste_bueno)
```






# Test hoslem


```{r}
library(ResourceSelection)
hoslem.test(entrenamiento$Enfermedad_Cardiaca_Ataque, fitted(ajuste_bueno), g = 8)
```

Nos da estos valores porque seguramente hayan variables que no se relacionen de forma lineal. 

Haya alguna variable o variables que no se relacionan de forma lineal con la inversa logit de la probabilidad. Es decir, que haya alguna variable o variables que tienen un punto en el q minimiza o maximiza la probabilidad y cuando se alejan de ese punto, esa probabilidad crece o decrece.


Como podemos observar en el resultado del test, tenemos un p-valor muy pequeño(p-valor = 2.2e-16), con lo que podemos concluir que  rechazamos nuestra hipotesis nula lo cual significaria que los datos no se ajustan al modelo.
El problema es la asumcion de probabilidad incremental en forma de inversa logistica. Nuestras variables parecen que no se relacionan linealmente con el logit de la probabilidad. 

# Prediccion


```{r}
prediccion <- predict(ajuste_bueno,test)
```

# CURVA ROC

```{r}
library(pROC)
par.roc <- roc(test$Enfermedad_Cardiaca_Ataque, prediccion)
par.roc
plot(par.roc)

```

La capacidad de clasifciación de este modelo es alta, porque el area bajo de la curva ROC es 0.8477 con un intervalo de confianza de (-), lo que indica claramente que es un buen modelo.




# ALTERNATIVA LASSO:

Primero tenemos que tipificar los datos para que todas las variables tengan las mismas unidades.

# ```{r}
# variables_numericas <- c("IMC", "Salud_Mental","Salud_Fisica")
# 
# datos_relativizados1 <- as.data.frame(scale(datos[, variables_numericas]))
# 
# datos_relativizados <- 
# 
# datos <- datos_relativizados
# 
# ```

Vamos a cargar los datos de nuevo:

```{r}

head(entrenamiento)


```



Para empezar con el modelo de Lasso tendremos que estimar landa con validación cruzada de esta forma:


```{r}
head(entrenamiento)

library(glmnet)
x <- model.matrix(Enfermedad_Cardiaca_Ataque ~ .,entrenamiento)
y <- entrenamiento$Enfermedad_Cardiaca_Ataque #vector de variable respuesta

```


```{r}
lambdas <- 10^seq(5,-3,length=100)
set.seed(12345)
cv.lasso <- cv.glmnet(x,y,alpha=1,lambda=lambdas)
plot(cv.lasso)
min(cv.lasso$cvm) #Mínimo error cuadrático medio de predicción
cv.lasso$lambda.min  # Alcanza el mínimo ECM
cv.lasso$lambda.1se  # Regla de un error estándar

```

Segun esta grafica, podemos observar que necesitaremos entre 13 y 19 covariables ya que la primera linea sabemos que indica el ECM minimo en escala logaritmica con log(lamnda) = -7 aproximadamente y la siguiente linea de puntos verticales indica el valor de landa que estaria a menos de 1 error estandard. Por tanto, nos interesa elegir el numero de covariables que se relaciona en esa linea de puntos que aproximadamente será entre 12 y 13 covariables. 

Pero si aplicamos la regla de 1 error estandard, realmente no se distinguir entre los lamndas cercanos a este primero. El mas grande, utilizando las reglas de un error estandard, seria la segunda linea. El ECM en esta linea, será mas grande que en la primera pero se diferencian en menos de 1 error estandard entonces no podemos diferenciar y no podemos saber cual es mejor porque esta dentro del rango de error de medida. 
Habitualmente elegimos un lamnda entre estas lineas, con un redondeo de 3 decimales. Por tanto, lamnda que elegimos es 0.005.

Por lo tanto seguimos con incertidumbre, y esa incertidumbre la medimos con intervalos de confianza que se construyen con los errores estandard. Nos dice hasta que putno estoy convencido del valor. 



Utilizando $\lambda =$ `r round(cv.lasso$lambda.1se,3)`, el error de predicción es:
```{r}
lasso.lambda1st <- glmnet(x,y,alpha=1,lambda=round(cv.lasso$lambda.1se,3))
pred.lasso.lambda1st <- predict(lasso.lambda1st,s=round(cv.lasso$lambda.1se,3),newx=x)
mean((pred.lasso.lambda1st-y)^2)
```
Una vez seleccionado el valor de $\lambda$, el tercer paso es recuperar todos los datos para obtener los estimadores lasso definitivos, comprobando qué predictores han quedado en el modelo (aquellos cuyo coeficiente sea distinto de cero):

```{r}
lasso_final <- glmnet(x,y,alpha=1,lambda =round(cv.lasso$lambda.1se,3))
coef(lasso_final)[coef(lasso_final)[,1] !=0,]
```


En este caso, aunque el error estimado de predicción sea un poco mayor, hemos reducido a la mitad el número de variables en el modelo.

Por tanto las variables seleccionadas segun Lasso son: Presion_Sanginea_Alta + Colesterol_Alto + IMC + Fumador + Ataque + Diabetes + Salud_General + Salud_Fisica + Dificultad_Andar + Sexo + Edad + Ingreso


```{r}
ajuste_lasso <- glm(Enfermedad_Cardiaca_Ataque ~ Presion_Sanginea_Alta + Colesterol_Alto + IMC + Fumador + Ataque + Diabetes + Salud_General + Salud_Fisica + Dificultad_Andar + Sexo + Edad + Ingreso, family = "binomial", data = entrenamiento)
summary(ajuste_lasso)
```

# Graficos: Validacion del modelo

El modelo lineal normal homocedástico basa sus resultados en diversas hipótesis que podrían no ser adecuadas para nuestros datos: linealidad, normalidad i homocedasticidad. Es conveniente contrastar estas hipótesis mediante el análisis de los residuos.


```{r}
par(mfrow = c(2,2))
plot(ajuste_lasso)
```

# Test de Hoslem

```{r}
library(ResourceSelection)
hoslem.test(entrenamiento$Enfermedad_Cardiaca_Ataque, fitted(ajuste_lasso), g = 8)
```


# Prediccion
```{r}
prediccion_lasso <- predict(ajuste_lasso,test)
```


# Curva ROC

```{r}
library(pROC)
par.roc <- roc(test$Enfermedad_Cardiaca_Ataque, prediccion_lasso)
par.roc
plot(par.roc)

```






















